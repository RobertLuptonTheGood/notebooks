{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the LSST Stack to display camera data\n",
    "\n",
    "This is a notebook that illustrates some of the ways that we have to interact with raw and rawish stack data.\n",
    "\n",
    "---\n",
    "\n",
    "Start with boilerplate importing libraries and setting up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import lsst.daf.persistence as dafPersist\n",
    "import lsst.afw.cameraGeom.utils as cameraGeomUtils\n",
    "import lsst.afw.display as afwDisplay\n",
    "import matplotlib.pyplot as plt   # Not needed for image displays, but used for analysis\n",
    "\n",
    "#%matplotlib inline \n",
    "%matplotlib ipympl\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#%matplotlib qt\n",
    "#%gui qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've choosen to display images using matplotlib by default.  The display interface is agnostic about the backend, do the display code will all work unmodified if you make a different choice.\n",
    "\n",
    "If you want to use matplotlib and stand-alone windows use the `qt` not `notebook` magic in the previous cell (or you may prefer `inline` -- still matplotlib but you won't overwrite your plots.  The downside is that you won't be able to zoom them either.)\n",
    "\n",
    "If you chose to use `ds9` or `firefly` you'll should change that here (assuming that firefly is running, as it is in LSST Science Platform environments); if you want to use the `ginga` backend you'll have some more fiddling to do that's not in scope for this notebook.\n",
    "\n",
    "Alternatively (and you'll see this in some of the cells) you can choose different backends for different displays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = \"matplotlib\"\n",
    "afwDisplay.setDefaultBackend(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a butler.  Here the repository is for the subset of RTM5 TS8 data that we have `rsync`ed to lsst-dev at NCSA.\n",
    "\n",
    "The butler does a number of things.  Basically, it \n",
    "- Maintains a database of what data exists and where it is\n",
    "- Knows how to return data (raw or processed) as suitable python objects\n",
    "- Manages calibration data (e.g. you'll see me ask it for the proper flat)\n",
    "\n",
    "The butler handles `dataId`s, which are basically dicts of keys, e.g. `dict(visit=269921586, ccd='S02')`.  The `visit` is the monotonically increasing number which the OCS passes to the TCS -- or will be!  At present we synthesize it from the timestamp.  If you don't want to be bothered with a `dataId` you can pass the identifiers in directly (or you can override fields in the `dataId` by writing them explicitly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    dataRoot = \"/datasets/comCam/repo/rtm5\"\n",
    "else:\n",
    "    dataRoot = \"/project/shared/BOT\"\n",
    "\n",
    "butler = dafPersist.Butler(dataRoot, calibRoot=os.path.join(dataPath, \"CALIB\"))\n",
    "dataType = \"run\"\n",
    "print(\"Available %ss: %s\" % (dataType,\n",
    "                             \" \".join([str(_) for _ in butler.queryMetadata('raw', [dataId])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the butler for a description of the camera.  This knows about CCD layout in the dewar, amplifier boundaries, gains, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = butler.get(\"camera\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't currently talk to the eTraveller directly.  I could import the eTraveller python code so that I can query it, but then I'd have to make sure that it worked transparently from lsst-dev.  This isn't ideal and we should address it, but for now I'll ask the butler what it knows.\n",
    "\n",
    "if False:\n",
    "   Here I want to know the visit numbers for all the 800nm flats that we ingested (in this case from just a couple of test runs)\n",
    "else:\n",
    "   Just look at some random BOT run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the butler for the raw file corresponding to the first visit for Raft `R10`, CCD `S20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    visit = butler.queryMetadata('raw', ['visit'], imageType='FLAT', wavelength=1000, run=4389)[0]\n",
    "else:\n",
    "    visit = butler.queryMetadata('raw', ['visit'], imageType='FLAT', run='6542D')[0]\n",
    "\n",
    "dataId = dict(visit=visit, raftName='R10', detectorName='S20')\n",
    "\n",
    "raw = butler.get('raw', dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And display it (unbinned) with an asinh/zscale stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = afwDisplay.Display(1, reopenPlot=True)\n",
    "disp.scale('asinh', 'zscale')\n",
    "\n",
    "disp.mtv(raw, title=\", \".join([str(_) for _ in dataId.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mentioned that the camera knows about the detector geometry.  Let's overlay that (and I'll zoom in so we can see what's going on if the display backend permits).  If you look at the help string you'll find that the colours are:\n",
    "-   Entire chip            ORANGE\n",
    "\n",
    "and\n",
    "-   HorizontalPrescan      YELLOW\n",
    "-   HorizontalOverscan     RED\n",
    "-   Data                   BLUE\n",
    "-   VerticalOverscan       MAGENTA \n",
    "\n",
    "for each amplifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.scale('asinh', 'zscale')\n",
    "disp.zoom(2, 350, 300)\n",
    "\n",
    "disp.mtv(raw, title=\", \".join([str(_) for _ in dataId.items()]))\n",
    "cameraGeomUtils.overlayCcdBoxes(raw.getDetector(), display=disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's trim the overscan and just show the data.  There are a number of ways to do this, all of which call the same code at the backend but behind different levels of syntactic sugar.\n",
    "\n",
    "Here's a generic command that can actually do a lot more than show an assembled CCD image.  It's reading the data, subtracting the median of each overscan region, assembling the image, and displaying it on `disp`.\n",
    "\n",
    "You might think that we could provide *more* sugar, and I agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = afwDisplay.Display(1, reopenPlot=True)\n",
    "disp.scale('asinh', 'zscale')\n",
    "\n",
    "#\n",
    "# Only display this subset of the detectors\n",
    "#\n",
    "detectorNameList=[]\n",
    "for rn, dn in butler.queryMetadata('raw', ['raftName', 'detectorName'], visit=dataId['visit'], raftName='R10'):\n",
    "    detectorNameList.append(f\"{rn}_{dn}\")\n",
    "                  \n",
    "cameraGeomUtils.showCamera(camera,\n",
    "                           cameraGeomUtils.ButlerImage(butler, \"raw\", visit=dataId[\"visit\"],\n",
    "                                                       callback=cameraGeomUtils.rawCallback),\n",
    "                           binSize=1, detectorNameList=detectorNameList, overlay=False, display=disp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the same command to show the entire camera, binned 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = afwDisplay.Display(1, reopenPlot=True)\n",
    "if False:\n",
    "    disp.scale('asinh', 'zscale')\n",
    "else:\n",
    "    disp.scale('asinh', 0, 4e4)\n",
    "\n",
    "dataType = \"raw\"\n",
    "mos = cameraGeomUtils.showCamera(camera,\n",
    "                                 cameraGeomUtils.ButlerImage(butler, dataType, visit=dataId[\"visit\"], verbose=False,\n",
    "                                                             callback=cameraGeomUtils.rawCallback),\n",
    "                                 binSize=64, display=disp, title=\"%d %s\" % (visit, dataType), overlay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'd be easier to see if we corrected for the gains.  I'll run a full ISR in a moment (overscan, bias, dark, flat), but for now we'll subtract the median of each amp.\n",
    "\n",
    "We *do* actually divide by the gain, but they are all set to 1.0 for now.  We used to use eotest values from some test run or other and some were 0 which made things significantly worse!\n",
    "\n",
    "To do this, we'll define a custom callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCallback(im, ccd, imageSource, subtractMedian=True):\n",
    "    \"\"\"Assemble the CCD image, subtracting the overscan and subtracting each amp's median\"\"\"\n",
    "\n",
    "    oim = cameraGeomUtils.rawCallback(im, ccd, imageSource,\n",
    "                                       subtractBias=True, correctGain=False)\n",
    "    if subtractMedian:\n",
    "        for a in ccd:\n",
    "            arr = oim[a.getBBox()].array\n",
    "            arr -= np.median(arr)\n",
    "\n",
    "    return oim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = afwDisplay.Display(1, reopenPlot=True)\n",
    "disp.scale('asinh', 'zscale')\n",
    "\n",
    "#\n",
    "# Only display this subset of the detectors\n",
    "#\n",
    "detectorNameList=[]\n",
    "for rn, dn in butler.queryMetadata('raw', ['raftName', 'detectorName'], visit=dataId['visit'], raftName='R10'):\n",
    "    detectorNameList.append(f\"{rn}_{dn}\")\n",
    "                  \n",
    "dataType = \"raw\"\n",
    "mos = cameraGeomUtils.showCamera(camera,\n",
    "                                 cameraGeomUtils.ButlerImage(butler, dataType, visit=dataId[\"visit\"],\n",
    "                                                             callback=myCallback),\n",
    "                                 binSize=8, detectorNameList=detectorNameList, display=disp, overlay=False,\n",
    "                                 title=\"%d %s - (per-amp median)\" % (visit, dataType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mentioned that there were various ways to trim and assemble the CCDs.  Here's the primitive that we use, and display it (if you have ds9 running, you could use`\"ds9\"` instead of \"matplotlib\" in the `Display` call).\n",
    "\n",
    "We'll run the full Instrument Signature Removal (ISR) code in a little bit, but this is the basic pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.ip.isr import AssembleCcdTask\n",
    "\n",
    "config = AssembleCcdTask.ConfigClass()          # Configuration options\n",
    "config.doTrim = True\n",
    "\n",
    "assembleTask = AssembleCcdTask(config=config)   # Build the object that'll do the work -- basically a functor\n",
    "\n",
    "raw = butler.get('raw', dataId)\n",
    "exposure = assembleTask.assembleCcd(raw)        # Do the work.\n",
    "\n",
    "disp = afwDisplay.Display(2, \"matplotlib\")\n",
    "disp.scale(\"asinh\", \"zscale\")\n",
    "\n",
    "disp.mtv(exposure, title=\"raw %d %s %s\" % (dataId[\"visit\"], dataId[\"raftName\"], dataId[\"detectorName\"]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I talked about raw and rawish stack data;  let's look at some master calibration files (and I'll turn off the overlay)\n",
    "\n",
    "There is magic here.  I specify the *data*'s visit number, and the butler returns the correct bias/dark/flat.  The underlying code is e.g. `butler.get('flat', visit=269921586, raftName='R10', detectorName='S20')` (where I've chosen to unpack the `dataId`)\n",
    "\n",
    "Here I'm looking at the whole raft -- I could have used e.g. `detectorNameList=['R10_S21', 'R10_S22']` to look at only selected chips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = afwDisplay.Display(1, reopenPlot=True)\n",
    "disp.scale('asinh', 'zscale')\n",
    "\n",
    "dataType = [\"bias\", \"dark\", \"flat\"][0]\n",
    "mos = cameraGeomUtils.showCamera(camera,\n",
    "                                 cameraGeomUtils.ButlerImage(butler, dataType, visit=dataId[\"visit\"], verbose=True),\n",
    "                                 detectorNameList=detectorNameList,\n",
    "                                 binSize=16, display=disp, overlay=False, title=\"%d %s\" % (visit, dataType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a callback to run the full ISR and mosaic up the results.  Because I don't want to read the bias and dark frames for each chip repeatedly (and am too lazy to cache them, and the caching in the butler is currently disabled due to concerns with constness) I'm actually going to turn the bias/dark processing off.\n",
    "\n",
    "This is not beautiful;  there's a DM issue in Jira to make it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.ip.isr import IsrTask\n",
    "\n",
    "config = IsrTask.ConfigClass()\n",
    "config.doBias = False\n",
    "config.doDark = False\n",
    "config.doFringe = False\n",
    "config.doLinearize = False\n",
    "config.doDefect = False\n",
    "config.doAddDistortionModel = False\n",
    "\n",
    "isrTask = IsrTask(config=config)\n",
    "\n",
    "def isrCallback(im, ccd, imageSource, isrTask=isrTask):\n",
    "    \"\"\"Run the ISR\"\"\"\n",
    "    dataId = imageSource.kwargs.copy()    # this is the ugly bit\n",
    "    dataId['ccd'] = ccd.getName()\n",
    "\n",
    "    if False and ccd.getName() == 'S00':\n",
    "        import pdb; pdb.set_trace()\n",
    "    if False:   # Avoid re-reading the data by reconstructing the Exposure; this is an ugly bit too\n",
    "        import lsst.afw.image as afwImage\n",
    "\n",
    "        raw = afwImage.makeExposure(afwImage.makeMaskedImage(im))\n",
    "        raw.setDetector(ccd)\n",
    "        raw.getInfo().setVisitInfo(afwImage.VisitInfo(exposureTime=1.0))\n",
    "    else:\n",
    "        raw = butler.get('raw', dataId)\n",
    "\n",
    "    bias = butler.get('bias', dataId) if config.doBias else None\n",
    "    dark = butler.get('dark', dataId) if config.doDark else None\n",
    "    flat = butler.get('flat', dataId)\n",
    "\n",
    "    # Returns a struct;  result.exposure is an Exposure\n",
    "    if False and ccd.getName() == 'S00':\n",
    "        import pdb; pdb.set_trace()\n",
    "    result = isrTask.run(raw, bias=bias, dark=dark, flat=flat)\n",
    "    arr = result.exposure.image.array\n",
    "\n",
    "    return result.exposure.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = afwDisplay.Display(1) # , backend='matplotlib')\n",
    "disp.scale('linear', 'zscale')\n",
    "\n",
    "mos = cameraGeomUtils.showCamera(camera, \n",
    "                                 cameraGeomUtils.ButlerImage(butler, \"raw\", visit=visit,\n",
    "                                                             verbose=True,\n",
    "                                                             callback=isrCallback),\n",
    "                                 #detectorNameList=['S10',],\n",
    "                                 binSize=4, overlay=True,\n",
    "                                 display=disp, title=\"Post-ISR %d\" % visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.scale('linear', 'zscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.display.firefly\n",
    "lsst.display.firefly.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our knowledge of the detector to make a histogram of the difference between serial and parallel overscan levels for all the CCDs in the raft.\n",
    "\n",
    "This is just an example; the `raw[amp.getRawHorizontalOverscanBBox()]` returns an image of the overscan for that amp, and the `.array` returns a `numpy` view of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "parallelOverscan = []\n",
    "serialOverscan   = []\n",
    "for ccd in camera:\n",
    "    raw = butler.get('raw', dataId, ccd=ccd.getName())\n",
    "    for amp in raw.getDetector():\n",
    "        names.append(\"%s-%s\" % (ccd.getName(), amp.getName()))\n",
    "        # Serial overscan\n",
    "        overscan = raw[amp.getRawHorizontalOverscanBBox()].image\n",
    "        serialOverscan.append(np.median(overscan.array))\n",
    "        # Parallel overscan (all on one line)\n",
    "        parallelOverscan.append(np.median(raw[amp.getRawVerticalOverscanBBox()].image.array))\n",
    "                \n",
    "names = np.array(names)\n",
    "parallelOverscan = np.array(parallelOverscan)\n",
    "serialOverscan   = np.array(serialOverscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ccd in [ccd.getName() for ccd in camera]:\n",
    "    l = np.char.rfind(names, ccd, 0) == 0\n",
    "    plt.hist((parallelOverscan - serialOverscan)[l], bins=np.linspace(-8, 12, 20), alpha=0.5, label=ccd)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Serial overscan - parallel overscan (DN)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
